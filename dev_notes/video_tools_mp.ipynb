{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6c74135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from moviepy import VideoFileClip, ImageClip, concatenate_videoclips, vfx\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(logging.Formatter(\n",
    "        '[%(levelname)s] %(asctime)s - %(name)s: %(message)s',\n",
    "        datefmt='%H:%M:%S'\n",
    "    ))\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "\n",
    "def get_logger(name: str = __name__):\n",
    "    \"\"\"Trả về logger cho module khác.\"\"\"\n",
    "    return logging.getLogger(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d6b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_resolution(path: str) -> tuple[int, int]:\n",
    "    \"\"\"Trả về (width, height) của video/ảnh.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    clip = VideoFileClip(path)\n",
    "    w, h = clip.size\n",
    "    clip.close()\n",
    "    return int(w), int(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c245cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_video(input_path: str, start: float, end: float):\n",
    "    \"\"\"\n",
    "    Cắt video từ giây `start` đến `end`.\n",
    "    \"\"\"\n",
    "    if end <= start:\n",
    "        raise ValueError(\"'end' phải lớn hơn 'start'.\")\n",
    "\n",
    "    logger.info(f\"Trimming {input_path} from {start}s to {end}s\")\n",
    "    clip = VideoFileClip(input_path).subclipped(start, end)\n",
    "    return clip\n",
    "\n",
    "\n",
    "def concat_videos(videos: list[str|VideoFileClip]):\n",
    "    \"\"\"Ghép nhiều video thành một.\"\"\"\n",
    "    if len(videos) < 2:\n",
    "        raise ValueError(\"Cần ít nhất 2 video để ghép.\")\n",
    "    clips= []\n",
    "    for v in videos:\n",
    "        if isinstance(v, str):\n",
    "            clips.append(VideoFileClip(v))\n",
    "        elif isinstance(v, VideoFileClip):\n",
    "            clips.append(v) \n",
    "        else:\n",
    "            raise TypeError(\"Only support VideoFileCLip or str\")\n",
    "\n",
    "    logger.info(f\"Concatenating {len(videos)} videos\")\n",
    "    final_clip = concatenate_videoclips(clips, method=\"chain\")\n",
    "    return final_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d9231f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import os\n",
    "root = \"D:/ThienPV/code/demo/data/\"\n",
    "img = root +\"img.jpg\"\n",
    "docs = root + \"sample_lesson.md\"\n",
    "video = root + \"TestAPI.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96962b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 11:27:43 - __main__: Trimming D:/ThienPV/code/demo/data/TestAPI.mp4 from 0s to 4.65s\n"
     ]
    }
   ],
   "source": [
    "# Test trim\n",
    "start = 0\n",
    "end = 4.65\n",
    "short_clip = trim_video(input_path=video, start=start, end=end)\n",
    "assert short_clip.duration == end -start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccbe16c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 11:33:07 - __main__: Concatenating 3 videos\n"
     ]
    }
   ],
   "source": [
    "concated_clip = concat_videos([short_clip,short_clip,short_clip])\n",
    "assert concated_clip.duration == 3 * short_clip.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d4112e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "from moviepy import VideoFileClip\n",
    "from PIL import Image\n",
    "\n",
    "def top_colors_first_frame(\n",
    "    video: Union[str, \"VideoFileClip\"],\n",
    "    top_k: int = 10,\n",
    "    quantize: int = 0,\n",
    "    resize_to: Optional[int] = None,\n",
    "    return_hex: bool = True,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Lấy frame đầu (t=0) và trả về top_k màu xuất hiện nhiều nhất.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    video       : đường dẫn hoặc VideoFileClip (MoviePy v2).\n",
    "    top_k       : số màu cần lấy (mặc định 10).\n",
    "    quantize    : bước lượng tử hoá kênh màu (0 = đếm màu chính xác).\n",
    "                  Ví dụ 16 -> gom màu theo bậc 16 (giảm nhiễu).\n",
    "    resize_to   : nếu set (vd 720), sẽ downscale cạnh dài của frame\n",
    "                  về <= giá trị này để tăng tốc đếm (không bắt buộc).\n",
    "    return_hex  : có trả kèm mã HEX hay không.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict] với mỗi phần tử:\n",
    "      {\n",
    "        \"rgb\": (r, g, b),\n",
    "        \"hex\": \"#RRGGBB\",   # nếu return_hex=True\n",
    "        \"count\": <số pixel>,\n",
    "        \"ratio\": <tỷ lệ pixel trên toàn frame>\n",
    "      }\n",
    "    \"\"\"\n",
    "    opened_here = False\n",
    "    clip = video\n",
    "    if isinstance(video, str):\n",
    "        clip = VideoFileClip(video)\n",
    "        opened_here = True\n",
    "    try:\n",
    "        frame = clip.get_frame(0.0)  # (H,W,3|4)\n",
    "    finally:\n",
    "        if opened_here:\n",
    "            clip.close()\n",
    "\n",
    "    # Chuẩn hoá về RGB uint8\n",
    "    if frame.ndim != 3 or frame.shape[2] < 3:\n",
    "        raise ValueError(\"Frame không hợp lệ (cần dạng HxWx3 hoặc HxWx4).\")\n",
    "    frame = frame[:, :, :3]\n",
    "    if frame.dtype != np.uint8:\n",
    "        # MoviePy đôi khi trả float [0..1]; chuẩn hoá về uint8\n",
    "        if frame.max() <= 1.0:\n",
    "            frame = np.clip(np.rint(frame * 255.0), 0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            frame = np.clip(np.rint(frame), 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Tùy chọn downscale để tăng tốc\n",
    "    if resize_to:\n",
    "        h, w = frame.shape[:2]\n",
    "        scale = resize_to / max(h, w) if max(h, w) > resize_to else 1.0\n",
    "        if scale < 1.0:\n",
    "            new_size = (int(w * scale), int(h * scale))\n",
    "            frame = np.array(Image.fromarray(frame).resize(new_size, Image.BILINEAR), dtype=np.uint8)\n",
    "\n",
    "    # Tùy chọn lượng tử hoá màu (gom cụm màu gần nhau)\n",
    "    if quantize and quantize > 1:\n",
    "        q = int(quantize)\n",
    "        frame = (frame.astype(np.int16) // q) * q + q // 2\n",
    "        frame = np.clip(frame, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Đếm nhanh bằng numpy.unique trên dtype cấu trúc\n",
    "    pixels = frame.reshape(-1, 3)\n",
    "    dtype = np.dtype([(\"r\", np.uint8), (\"g\", np.uint8), (\"b\", np.uint8)])\n",
    "    structured = pixels.view(dtype)\n",
    "    uniques, counts = np.unique(structured, return_counts=True)\n",
    "\n",
    "    if counts.size == 0:\n",
    "        return []\n",
    "\n",
    "    # Lấy top_k bằng argpartition (O(n))\n",
    "    k = min(top_k, counts.size)\n",
    "    idx = np.argpartition(-counts, kth=k - 1)[:k]\n",
    "    idx = idx[np.argsort(-counts[idx])]  # sắp xếp lại theo count giảm dần\n",
    "\n",
    "    total = pixels.shape[0]\n",
    "    results: List[Dict] = []\n",
    "    for i in idx:\n",
    "        r, g, b = int(uniques[i][\"r\"]), int(uniques[i][\"g\"]), int(uniques[i][\"b\"])\n",
    "        cnt = int(counts[i])\n",
    "        item: Dict[str, object] = {\"rgb\": (r, g, b), \"count\": cnt, \"ratio\": cnt / total}\n",
    "        if return_hex:\n",
    "            item[\"hex\"] = f\"#{r:02X}{g:02X}{b:02X}\"\n",
    "        results.append(item)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57731249",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_color = top_colors_first_frame(video = short_clip, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65b5b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.fx.MaskColor import MaskColor\n",
    "\n",
    "no_bg_clip = MaskColor(color = background_color[0][\"rgb\"], threshold= 20, stiffness=1).apply(short_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8364aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bg_clip.save_frame(filename=\"temp.png\",t=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c5c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def overlay_background(fg_path: str, bg_path: str, output_path: str,\n",
    "                       position: tuple[int, int] = (0, 0), scale: float = 1.0,\n",
    "                       bg_loop: bool = True, duration: float | None = None):\n",
    "    \"\"\"\n",
    "    Overlay video foreground (đã xóa nền) lên background.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Overlaying {fg_path} on {bg_path} → {output_path}\")\n",
    "\n",
    "    # Load background\n",
    "    if bg_path.lower().endswith((\".jpg\", \".png\", \".jpeg\", \".webp\")):\n",
    "        bg_clip = ImageClip(bg_path)\n",
    "        if duration:\n",
    "            bg_clip = bg_clip.with_duration(duration)\n",
    "        elif bg_loop:\n",
    "            temp_fg = VideoFileClip(fg_path)\n",
    "            bg_clip = bg_clip.with_duration(temp_fg.duration)\n",
    "            temp_fg.close()\n",
    "    else:\n",
    "        bg_clip = VideoFileClip(bg_path)\n",
    "        if duration:\n",
    "            bg_clip = bg_clip.subclip(0, duration)\n",
    "\n",
    "    # Load foreground\n",
    "    fg_clip = VideoFileClip(fg_path)\n",
    "    if scale != 1.0:\n",
    "        fg_clip = fg_clip.resize(scale)\n",
    "\n",
    "    # Overlay\n",
    "    final = bg_clip.overlay(fg_clip, position=position)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27f19312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "def overlay(fg, bg,\n",
    "            position: tuple[int, int] = (0, 0), relative:bool= False, scale: float = 1.0,\n",
    "            bg_loop: bool = True, duration: float | None = None):\n",
    "    \"\"\"\n",
    "    Overlay video foreground (đã xóa nền) lên background.\n",
    "    \"\"\"\n",
    "    # Load foreground\n",
    "    if isinstance(fg,str):\n",
    "        fg_clip = VideoFileClip(fg)\n",
    "    else:\n",
    "        fg_clip = fg\n",
    "    # Load background\n",
    "    if isinstance(bg, str):\n",
    "        if bg.lower().endswith((\".jpg\", \".png\", \".jpeg\", \".webp\")):\n",
    "            bg_clip = ImageClip(bg)\n",
    "            if duration:\n",
    "                bg_clip = bg_clip.with_duration(duration)\n",
    "            elif bg_loop:\n",
    "                bg_clip = bg_clip.with_duration(fg_clip.duration)\n",
    "\n",
    "        else:\n",
    "            bg_clip = VideoFileClip(bg)\n",
    "            if duration:\n",
    "                bg_clip = bg_clip.subclip(0, duration)\n",
    "    else:\n",
    "        bg_clip = bg\n",
    "\n",
    "    if scale != 1.0:\n",
    "        fg_clip = fg_clip.resized(scale)\n",
    "\n",
    "    # Overlay\n",
    "    final = CompositeVideoClip([bg_clip,fg_clip.with_position(position, relative = relative)])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef840a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/ThienPV/code/demo/data/img.jpg'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb0d444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlayed = overlay(fg = no_bg_clip, bg=img,scale=0.1, position=(0,0), relative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d74a2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlayed.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d420d7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
